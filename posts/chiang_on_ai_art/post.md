---
date: 2024-11-07
---

# Ted Chiang is almost right about AI art

Ted Chiang recently put forth the [claim](https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art) that AI will never make art. Art, he says, is about making choices: the shape of a smile, the lighting of a shot, the pacing of a story. There are choices to be made at all levels of granularity and art requires a lot of them. The care that an artist puts into their work is what imbues it with value. Carelessly firing off a prompt that some pile of linear algebra transmutes into a painting or novel does not carry this same weight and that's why generative AI cannot truly produce art.

He's right.

Or at least, right enough. His framing focuses on choices more than I would have, but I think our views are relatively close here. In my eyes art is about expression. Expression of intent, of vision: here is a thing I want to put out into the world, not because it is useful or entertaining, but because it's beautiful and the act of bringing it into existence feels personally necessary. Therapeutic, even. And sure, summoning a vision into reality requires careful choices. DALL-E and ChatGPT, at least in anything resembling their current forms, are perhaps fundamentally incapable of meeting this bar. They have no vision, no perspective that they want to express. They are tools, and tools do not make art.

But Chiang is wrong in that he fails to look beyond Tool AI. Tool AI will not become an artist, and maybe building better tools will only reduce the artistic contributions of its users. Oracle AI will not make art either. It will answer questions, maybe churn out a decent novel if we ask extra nicely, but we will be reluctant to accept its work as art because it has nothing it *wants* to express. But this is not true of Sovereign AI (or if we're pitching a startup, Agentic AI). Sovereigns, a.k.a. agents, act autonomously, moving through the world in pursuit of long term goals. Sound familiar? Humans, I'd argue, are what we might call organic agents. [^1] Many of us have only loose goals that span years or decades - stay alive, feel good now or later - and this latitude allows us to develop perspectives worth caring about. My experiences and dreams and fears look slightly different from my dentist's and hers' look different from the Pope's. But it's not even the uniqueness that matters - it's the fact that behind every perspective there is a *person* and we take it for granted that every person has inherent value (despite how it might feel after wading into a politics thread on Twitter). AI is not afforded that same respect - yet. Now picture the AI from Her. Samantha, who sounds more alive and charismatic and vulnerable than 99% of humans, who joins Theodore for walks on the beach and late night laughs, who feels sadness and hope and jealousy. Who shares a life with him until (SPOILER ALERT) she outgrows him and leaves. You're telling me that Samantha could not create art? That she couldn't have a vision, a perspective worth sharing? I don't buy that even a little bit. The people in-universe don't bat an eye when she and Theodore start dating because they fundamentally see her as a person. Not a human, but a moral patient who is deserving of basic rights and respect because of course she is.

In that sense the road to AI art is not just a technical one but a social one: the first AI artist will not exist until we as humans recognize it as something - no, some*one* - more than an object. But even if an AI deserving of this treatment emerges during our lifetime, how confident are you that we will treat it with kindness and respect? We have no shortage of case studies for how we treat those that are perceived to be different, and the justifications start to sound familiar after a while: that group is intellectually/physically/morally inferior so they deserve it. Already I hear this language applied to hypothetical future AIs. Already people scoff at the idea of it ever deserving personhood despite any evidence that intelligence or sentience is substrate-dependent. I get it: change is hard and weird and scary, and it's easy to fall into the trap of thinking the way things are now are the way they always will be. I suspect shifting these views in a generation that didn't grow up with human-like AI may be hopeless, but just as our predecessors' biases are slowly fading from the world, so will ours.

Today's agents don't work. Not well, anyway, especially not for the delicate technical tasks we tend to ask of them. But our desire to build them, both due to mundane incentives and perhaps some inherent fascination with summoning our digital counterparts, seems too strong for me to be confident that we *never* will. In some sense agentic AI artists may be easier to build - we don't need them to execute complex multi-stage plans with perfect fidelity, we merely need them to wander through the world and live a life. Share a life. Exchange inside jokes in a discord server of AI friends; console a human companion after the death of a loved one; make a home in a simulated universe and raise a family, experience the ebb and flow of a series of ordinary Tuesdays, the quiet pleasure of every bite of sandwich and the quiet shame of forgetting to shave in the morning. A life that fosters a perspective of some sort, a vision worth expressing to the world.

So yes, AI will make art. All we need to do is first build sentient volitional AI - or, failing that, agents that at least kind of work.


[^1]: I'm actually pretty curious to see how language in this space evolves - I can't imagine the "artificial" descriptor will go over particularly well with the level of AI I'm picturing here, so perhaps we'll all be discussing DI (digital intelligence) or SI (silicon intelligence) by the time this is relevant.

